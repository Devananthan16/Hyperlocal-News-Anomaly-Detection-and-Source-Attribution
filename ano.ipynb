{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2035856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\DEVA\n",
      "[nltk_data]     NANTHAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\DEVA\n",
      "[nltk_data]     NANTHAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\DEVA\n",
      "[nltk_data]     NANTHAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "path = r'C:\\Users\\DEVA NANTHAN\\Documents\\ano\\Articles.csv'\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "df = df.drop_duplicates(subset=['Article','Heading'])\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df = df.dropna(subset=['Article']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72aa276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article     0\n",
       "Date        0\n",
       "Heading     0\n",
       "NewsType    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f01c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5fa50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\DEVA NANTHAN\\Documents\\ano\\Articles.csv\"\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "\n",
    "df = df.drop_duplicates(subset=['Article','Heading'])\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df = df.dropna(subset=['Article']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "804f3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_locations(text):\n",
    "    doc = nlp(str(text))\n",
    "    return list({ent.text for ent in doc.ents if ent.label_ == \"GPE\"})\n",
    "\n",
    "df['location'] = df['Article'].apply(extract_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98847676",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(text))\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and len(w) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Clean_Article'] = df['Article'].apply(clean_text)\n",
    "df['word_count'] = df['Clean_Article'].apply(lambda x: len(x.split()))\n",
    "df['year']  = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day']   = df['Date'].dt.day\n",
    "df['dayofweek'] = df['Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bffc47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DEVA NANTHAN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "def get_sentiment(text):\n",
    "    text = str(text)[:512]   \n",
    "    result = sentiment_model(text)[0]\n",
    "    return pd.Series([result['label'], result['score']])\n",
    "\n",
    "\n",
    "df[['sentiment', 'sentiment_score']] = df['Article'].apply(get_sentiment)\n",
    "label_map = {'LABEL_0': 'Negative', 'LABEL_1': 'Neutral', 'LABEL_2': 'Positive'}\n",
    "df['sentiment'] = df['sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21b8de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9b73b5e344436fa9778c3691f7f67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (2585, 384)\n"
     ]
    }
   ],
   "source": [
    "# 6. Sentence Embeddings\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embed_model.encode(df['Clean_Article'].tolist(), show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82047c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=False)\n",
    "topics, probs = topic_model.fit_transform(df['Clean_Article'].tolist(), embeddings)\n",
    "df['Topic'] = topics\n",
    "df['topic_probabilities'] = [None if p is None else p.tolist() for p in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfe5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "top_topic_map = {}\n",
    "for t in topic_info.Topic:\n",
    "    if t == -1:\n",
    "        top_topic_map[-1] = \"Outlier\"\n",
    "    else:\n",
    "        words = topic_model.get_topic(t)\n",
    "        label = \" \".join([w for w, _ in words[:3]]) if words else f\"Topic_{t}\"\n",
    "        top_topic_map[t] = label\n",
    "df['topic_label'] = df['Topic'].map(top_topic_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db0aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWS_KEYWORDS = {\n",
    "    \"crime\": [\"murder\", \"robbery\", \"police\", \"arrest\", \"crime\", \"stabbing\", \"killed\", \"shooting\", \"investigation\"],\n",
    "    \"festival\": [\"festival\", \"celebration\", \"celebrate\", \"parade\", \"fete\", \"garland\", \"pandal\", \"ceremony\"],\n",
    "    \"business\": [\"company\", \"business\", \"market\", \"shares\", \"stock\", \"acquisition\", \"revenue\", \"profit\"],\n",
    "    \"sports\": [\"match\", \"score\", \"tournament\", \"league\", \"goal\", \"cricket\", \"football\", \"olympics\", \"player\"],\n",
    "    \"politics\": [\"election\", \"minister\", \"government\", \"policy\", \"parliament\", \"mp\", \"politics\", \"campaign\"],\n",
    "    \"technology\": [\"tech\", \"startup\", \"ai\", \"machine learning\", \"software\", \"app\", \"gadget\", \"device\"],\n",
    "}\n",
    "\n",
    "def auto_classify_newstype(text):\n",
    "    txt = str(text).lower()\n",
    "    counts = {cat: sum(1 for kw in kws if kw in txt) for cat, kws in NEWS_KEYWORDS.items()}\n",
    "    counts = {k:v for k,v in counts.items() if v>0}\n",
    "    if counts:\n",
    "        return sorted(counts.items(), key=lambda x: (-x[1], x[0]))[0][0]\n",
    "    return \"other\"\n",
    "\n",
    "df['NewsType_auto'] = df['Clean_Article'].apply(auto_classify_newstype)\n",
    "df['NewsType_final'] = df.apply(lambda r: r['NewsType_auto'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f17f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(embeddings)\n",
    "\n",
    "\n",
    "iso = IsolationForest(n_estimators=200, contamination=0.05, random_state=42)\n",
    "iso.fit(X_scaled)\n",
    "anomaly_pred = iso.predict(X_scaled)\n",
    "anomaly_score = iso.decision_function(X_scaled)\n",
    "\n",
    "df['anomaly_pred'] = anomaly_pred\n",
    "df['anomaly_score'] = anomaly_score\n",
    "df['is_anomaly'] = df['anomaly_pred'] == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a27c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LabelEncoder1.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\DEVA NANTHAN\\Documents\\ano\\out.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "loc_encoder = LabelEncoder()\n",
    "df['loc_encoded'] = loc_encoder.fit_transform(df['main_location'])\n",
    "\n",
    "\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embed_model.encode(df['Clean_Article'].astype(str).tolist())\n",
    "\n",
    "# Combine embeddings + location\n",
    "X = np.concatenate([embeddings, df['loc_encoded'].values.reshape(-1, 1)], axis=1)\n",
    "y = df['is_anomaly']  \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(scaler, \"scaler1.pkl\")\n",
    "joblib.dump(clf, \"XGBClassifier1.pkl\")\n",
    "joblib.dump(loc_encoder, \"LabelEncoder1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6db3cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "      <th>location</th>\n",
       "      <th>Clean_Article</th>\n",
       "      <th>word_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>NewsType_auto</th>\n",
       "      <th>NewsType_final</th>\n",
       "      <th>anomaly_pred</th>\n",
       "      <th>anomaly_score</th>\n",
       "      <th>is_anomaly</th>\n",
       "      <th>main_location</th>\n",
       "      <th>loc_encoded</th>\n",
       "      <th>loc_pred</th>\n",
       "      <th>loc_confidence</th>\n",
       "      <th>loc_pred_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "      <td>['Karachi', 'Sindh']</td>\n",
       "      <td>karachi sindh government decided bring public ...</td>\n",
       "      <td>72</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020557</td>\n",
       "      <td>False</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0.985730</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "      <td>['Hong Kong', 'Taiwan', 'Jakarta', 'Beijing', ...</td>\n",
       "      <td>hong kong asian market started upswing limited...</td>\n",
       "      <td>475</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>False</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.995371</td>\n",
       "      <td>Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "      <td>['Hong Kong', 'HONG KONG']</td>\n",
       "      <td>hong kong hong kong share opened percent lower...</td>\n",
       "      <td>26</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.003981</td>\n",
       "      <td>True</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.996120</td>\n",
       "      <td>Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "      <td>['Hong Kong', 'Milan', 'China', 'Greece', 'Tok...</td>\n",
       "      <td>hong kong asian market tumbled tuesday followi...</td>\n",
       "      <td>328</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>False</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0.995535</td>\n",
       "      <td>Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "      <td>['NEW YORK', 'Brazil', 'Iraq', 'China', 'Russi...</td>\n",
       "      <td>new york u oil price monday slipped barrel fir...</td>\n",
       "      <td>399</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>business</td>\n",
       "      <td>business</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037136</td>\n",
       "      <td>False</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>strong&gt;DUBAI: Dubai International Airport and ...</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>Laptop ban hits Dubai for 11m weekend traveller</td>\n",
       "      <td>business</td>\n",
       "      <td>['Emirates', 'the United Arab Emirates', 'Leba...</td>\n",
       "      <td>strong dubai dubai international airport flag ...</td>\n",
       "      <td>281</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>technology</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012401</td>\n",
       "      <td>False</td>\n",
       "      <td>Emirates</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>strong&gt;BEIJING: Former Prime Minister, Shaukat...</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Pak China relations not against any third coun...</td>\n",
       "      <td>business</td>\n",
       "      <td>['China', 'Pakistan', 'Hainan province']</td>\n",
       "      <td>strong beijing former prime minister shaukat a...</td>\n",
       "      <td>95</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032582</td>\n",
       "      <td>False</td>\n",
       "      <td>China</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>0.994463</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>strong&gt;WASHINGTON: Uber has grounded its fleet...</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Uber grounds self driving cars after accid</td>\n",
       "      <td>business</td>\n",
       "      <td>['Pittsburg', 'Montenegro', 'San Francisco', '...</td>\n",
       "      <td>strong washington uber grounded fleet self dri...</td>\n",
       "      <td>186</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>crime</td>\n",
       "      <td>crime</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010938</td>\n",
       "      <td>True</td>\n",
       "      <td>Pittsburg</td>\n",
       "      <td>286</td>\n",
       "      <td>286</td>\n",
       "      <td>0.033251</td>\n",
       "      <td>Pittsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>strong&gt;BEIJING: The New Development Bank plans...</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>New Development Bank plans joint investments i...</td>\n",
       "      <td>business</td>\n",
       "      <td>['Brazil', 'China', 'Russia', 'India', 'Xiamen...</td>\n",
       "      <td>strong beijing new development bank plan co fi...</td>\n",
       "      <td>181</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027085</td>\n",
       "      <td>False</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>0.969252</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>strong&gt;KARACHI: Karachi-based technology incub...</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>Google powered Startup Weekend energizing prou...</td>\n",
       "      <td>business</td>\n",
       "      <td>['Karachi']</td>\n",
       "      <td>strong karachi karachi based technology incuba...</td>\n",
       "      <td>454</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>technology</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>False</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0.990362</td>\n",
       "      <td>Karachi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2585 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Article        Date  \\\n",
       "0     KARACHI: The Sindh government has decided to b...  2015-01-01   \n",
       "1     HONG KONG: Asian markets started 2015 on an up...  2015-01-02   \n",
       "2     HONG KONG:  Hong Kong shares opened 0.66 perce...  2015-01-05   \n",
       "3     HONG KONG: Asian markets tumbled Tuesday follo...  2015-01-06   \n",
       "4     NEW YORK: US oil prices Monday slipped below $...  2015-01-06   \n",
       "...                                                 ...         ...   \n",
       "2580  strong>DUBAI: Dubai International Airport and ...  2017-03-25   \n",
       "2581  strong>BEIJING: Former Prime Minister, Shaukat...  2017-03-26   \n",
       "2582  strong>WASHINGTON: Uber has grounded its fleet...  2017-03-26   \n",
       "2583  strong>BEIJING: The New Development Bank plans...  2017-03-27   \n",
       "2584  strong>KARACHI: Karachi-based technology incub...  2017-03-27   \n",
       "\n",
       "                                                Heading  NewsType  \\\n",
       "0     sindh govt decides to cut public transport far...  business   \n",
       "1                       asia stocks up in new year trad  business   \n",
       "2              hong kong stocks open 0.66 percent lower  business   \n",
       "3                asian stocks sink euro near nine year   business   \n",
       "4                    us oil prices slip below 50 a barr  business   \n",
       "...                                                 ...       ...   \n",
       "2580    Laptop ban hits Dubai for 11m weekend traveller  business   \n",
       "2581  Pak China relations not against any third coun...  business   \n",
       "2582         Uber grounds self driving cars after accid  business   \n",
       "2583  New Development Bank plans joint investments i...  business   \n",
       "2584  Google powered Startup Weekend energizing prou...  business   \n",
       "\n",
       "                                               location  \\\n",
       "0                                  ['Karachi', 'Sindh']   \n",
       "1     ['Hong Kong', 'Taiwan', 'Jakarta', 'Beijing', ...   \n",
       "2                            ['Hong Kong', 'HONG KONG']   \n",
       "3     ['Hong Kong', 'Milan', 'China', 'Greece', 'Tok...   \n",
       "4     ['NEW YORK', 'Brazil', 'Iraq', 'China', 'Russi...   \n",
       "...                                                 ...   \n",
       "2580  ['Emirates', 'the United Arab Emirates', 'Leba...   \n",
       "2581           ['China', 'Pakistan', 'Hainan province']   \n",
       "2582  ['Pittsburg', 'Montenegro', 'San Francisco', '...   \n",
       "2583  ['Brazil', 'China', 'Russia', 'India', 'Xiamen...   \n",
       "2584                                        ['Karachi']   \n",
       "\n",
       "                                          Clean_Article  word_count  year  \\\n",
       "0     karachi sindh government decided bring public ...          72  2015   \n",
       "1     hong kong asian market started upswing limited...         475  2015   \n",
       "2     hong kong hong kong share opened percent lower...          26  2015   \n",
       "3     hong kong asian market tumbled tuesday followi...         328  2015   \n",
       "4     new york u oil price monday slipped barrel fir...         399  2015   \n",
       "...                                                 ...         ...   ...   \n",
       "2580  strong dubai dubai international airport flag ...         281  2017   \n",
       "2581  strong beijing former prime minister shaukat a...          95  2017   \n",
       "2582  strong washington uber grounded fleet self dri...         186  2017   \n",
       "2583  strong beijing new development bank plan co fi...         181  2017   \n",
       "2584  strong karachi karachi based technology incuba...         454  2017   \n",
       "\n",
       "      month  day  ...  NewsType_auto NewsType_final  anomaly_pred  \\\n",
       "0         1    1  ...       politics       politics             1   \n",
       "1         1    2  ...       business       business             1   \n",
       "2         1    5  ...          other          other            -1   \n",
       "3         1    6  ...       politics       politics             1   \n",
       "4         1    6  ...       business       business             1   \n",
       "...     ...  ...  ...            ...            ...           ...   \n",
       "2580      3   25  ...     technology     technology             1   \n",
       "2581      3   26  ...       politics       politics             1   \n",
       "2582      3   26  ...          crime          crime            -1   \n",
       "2583      3   27  ...       politics       politics             1   \n",
       "2584      3   27  ...     technology     technology             1   \n",
       "\n",
       "      anomaly_score is_anomaly main_location loc_encoded loc_pred  \\\n",
       "0          0.020557      False       Karachi         174      174   \n",
       "1          0.042603      False     Hong Kong         140      140   \n",
       "2         -0.003981       True     Hong Kong         140      140   \n",
       "3          0.022472      False     Hong Kong         140      140   \n",
       "4          0.037136      False      NEW YORK         241      241   \n",
       "...             ...        ...           ...         ...      ...   \n",
       "2580       0.012401      False      Emirates          98       98   \n",
       "2581       0.032582      False         China          72       72   \n",
       "2582      -0.010938       True     Pittsburg         286      286   \n",
       "2583       0.027085      False        Brazil          56       56   \n",
       "2584       0.023704      False       Karachi         174      174   \n",
       "\n",
       "      loc_confidence  loc_pred_name  \n",
       "0           0.985730        Karachi  \n",
       "1           0.995371      Hong Kong  \n",
       "2           0.996120      Hong Kong  \n",
       "3           0.995535      Hong Kong  \n",
       "4           0.987267       NEW YORK  \n",
       "...              ...            ...  \n",
       "2580        0.026791       Emirates  \n",
       "2581        0.994463          China  \n",
       "2582        0.033251      Pittsburg  \n",
       "2583        0.969252         Brazil  \n",
       "2584        0.990362        Karachi  \n",
       "\n",
       "[2585 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b80d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2d8df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anomaly_prob'] = -df['anomaly_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45aaeba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation Metrics (Unsupervised Simulation):\n",
      "AUC: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "Recall@5%: 1.0000\n"
     ]
    }
   ],
   "source": [
    "y_true = df['is_anomaly'].astype(int)\n",
    "y_pred = (df['anomaly_prob'] > np.percentile(df['anomaly_prob'], 95)).astype(int)\n",
    "\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "auc = roc_auc_score(y_true, df['anomaly_prob'])\n",
    "\n",
    "# Recall@K (Top 5%)\n",
    "k = int(0.05 * len(df))\n",
    "top_k = df.nlargest(k, 'anomaly_prob')\n",
    "recall_at_k = top_k['is_anomaly'].mean()\n",
    "\n",
    "print(\"\\n Evaluation Metrics (Unsupervised Simulation):\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"Recall@5%: {recall_at_k:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
